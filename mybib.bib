@Book{RussellNorvig2022,
  author    = {Russell, Stuart J and Norvig, Peter},
  publisher = {Prentice Hall},
  title     = {Artificial Intelligence: A Modern Approach},
  year      = {2022},
  edition   = {4th},
}

@inproceedings{Amado2022,
author = {Leonardo R. Amado and Reuth Mirsky and Felipe Meneguzzi},
title = {{Goal Recognition as Reinforcement Learning}},
booktitle = {Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI)},
year = {2022},
publisher = {AAAI Press},
abstract = {Most approaches for goal recognition rely on specifications of the possible dynamics of the actor in the environment when pursuing a goal. These specifications suffer from two key issues. 
First, encoding these dynamics requires careful design by a domain expert, which is often not robust to noise at recognition time. 
Second, existing approaches often need costly real-time computations to reason about the likelihood of each potential goal.
In this paper, we develop a framework that combines model-free reinforcement learning and goal recognition to alleviate the need for careful, manual domain design, and the need for costly online executions.
This framework consists of two main stages: offline learning of policies or utility functions for each potential goal, and online inference. 
We provide a first instance of this framework using tabular Q-learning for the learning stage, as well as three mechanisms for the inference stage. 
The resulting instantiation achieves state-of-the-art performance against goal recognizers on standard evaluation domains and superior performance in noisy environments.}
}

@Comment{jabref-meta: databaseType:bibtex;}
